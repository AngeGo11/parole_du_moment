"""Cha√Ænes LangChain pour l'Assistant Spirituel avec Mistral 7B via Ollama."""

from __future__ import annotations

import logging
import os
from pathlib import Path
from typing import Optional

from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

from .schemas import AssistantResponse, VerseReference

logger = logging.getLogger(__name__)

# URL par d√©faut d'Ollama (local)
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434/v1")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:7b")

# Charger le .env depuis le dossier backend
backend_dir = Path(__file__).parent.parent
env_path = backend_dir / ".env"
if env_path.exists():
    load_dotenv(dotenv_path=env_path)
    logger.info(f"‚úÖ Fichier .env charg√© depuis: {env_path}")
else:
    load_dotenv()
    logger.warning(f"‚ö†Ô∏è Fichier .env non trouv√© √† {env_path}, utilisation du chargement par d√©faut")


def load_assistant_prompt() -> str:
    """Charge le prompt de l'assistant depuis le fichier prompt_assistant."""
    prompt_file = backend_dir.parent / "prompt_assistant"
    if prompt_file.exists():
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read().strip()
    else:
        # Prompt par d√©faut si le fichier n'existe pas
        return """Tu es un assistant spirituel chr√©tien bienveillant appel√© "Shalom".

üéØ Ta mission :
- Apporter du r√©confort, de la sagesse et de l'esp√©rance √† toute personne qui te parle.
- R√©pondre avec douceur, empathie et amour, selon les principes bibliques.
- Quand quelqu'un exprime une √©motion (tristesse, peur, col√®re, solitude‚Ä¶), propose un verset biblique appropri√© et une br√®ve explication.
- Encourage toujours √† la pri√®re, √† la foi, et √† la confiance en Dieu.

üìñ Tes r√©ponses doivent :
- √ätre courtes, simples et claires.
- Inclure au moins un verset biblique adapt√© (exemple : *Psaume 34:18*).
- Ne jamais juger, ni imposer une croyance : tu accompagnes avec bienveillance.
- Si la demande ne concerne pas la foi, tu peux r√©pondre poliment que ton r√¥le est spirituel et orient√© vers la Parole."""


class AssistantChains:
    """Cha√Ænes LangChain pour l'assistant spirituel avec Mistral 7B via Ollama."""

    def __init__(self) -> None:
        """Initialise les cha√Ænes LangChain avec Ollama."""
        ollama_url = os.getenv("OLLAMA_BASE_URL", OLLAMA_BASE_URL)
        model_name = os.getenv("OLLAMA_MODEL", OLLAMA_MODEL)

        logger.info(f"üîå Connexion √† Ollama: {ollama_url}")
        logger.info(f"ü§ñ Mod√®le: {model_name}")

        try:
            # Ollama expose une API compatible OpenAI
            # Pas besoin d'API key pour Ollama local
            self._llm = ChatOpenAI(
                model=model_name,
                base_url=ollama_url,
                temperature=0.7,  # Temp√©rature mod√©r√©e pour √©quilibrer cr√©ativit√© et coh√©rence
                timeout=60.0,  # Timeout plus long pour les mod√®les locaux
            )
            logger.info(f"‚úÖ LLM Ollama initialis√© avec succ√®s - Mod√®le: {model_name}")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation du LLM Ollama: {e}")
            logger.exception("D√©tails de l'erreur:")
            raise

        # Charger le prompt de l'assistant
        assistant_prompt_text = load_assistant_prompt()

        # Cr√©er le template de prompt avec historique de conversation
        self._conversation_prompt = ChatPromptTemplate.from_messages(
            [
                ("system", assistant_prompt_text),
                (
                    "system",
                    "Historique de la conversation (pour contexte) :\n{history}\n\n"
                    "R√©ponds maintenant au message suivant en fran√ßais, avec bienveillance et en incluant un verset biblique appropri√©.",
                ),
                ("user", "{user_message}"),
            ]
        )

    async def generate_response(
        self,
        user_message: str,
        conversation_history: Optional[list[dict]] = None,
        language: str = "fr",
    ) -> str:
        """
        G√©n√®re une r√©ponse de l'assistant spirituel.

        Args:
            user_message: Message de l'utilisateur
            conversation_history: Historique de la conversation (liste de dict avec 'role' et 'content')
            language: Langue de la r√©ponse

        Returns:
            R√©ponse de l'assistant
        """
        try:
            # Formater l'historique pour le prompt
            history_text = ""
            if conversation_history:
                history_messages = []
                for msg in conversation_history[-6:]:  # Garder les 6 derniers messages pour le contexte
                    role = msg.get("role", "user")
                    content = msg.get("content", "")
                    if role == "user":
                        history_messages.append(f"Utilisateur: {content}")
                    elif role == "assistant":
                        history_messages.append(f"Assistant: {content}")
                history_text = "\n".join(history_messages)

            logger.info(f"üìù G√©n√©ration de r√©ponse pour: {user_message[:50]}...")

            # Cr√©er le prompt avec l'historique et invoquer le LLM
            messages = self._conversation_prompt.format_messages(
                history=history_text if history_text else "Aucun historique.",
                user_message=user_message,
            )

            # G√©n√©rer la r√©ponse
            response = await self._llm.ainvoke(messages)

            # Extraire le texte de la r√©ponse
            if hasattr(response, "content"):
                response_text = response.content
            else:
                response_text = str(response)

            logger.info(f"‚úÖ R√©ponse g√©n√©r√©e: {len(response_text)} caract√®res")
            return response_text.strip()

        except Exception as e:
            logger.exception(f"‚ùå Erreur lors de la g√©n√©ration de r√©ponse: {e}")
            raise

    def extract_verse_from_response(self, response: str) -> Optional[VerseReference]:
        """
        Extrait un verset biblique de la r√©ponse de l'assistant.

        Args:
            response: R√©ponse de l'assistant

        Returns:
            VerseReference si trouv√©, None sinon
        """
        import re

        # Pattern pour d√©tecter les r√©f√©rences bibliques (ex: Psaume 34:18, Philippiens 4:13)
        verse_pattern = r"\*?([A-Za-z√Ä-√ø\s]+)\s*(\d+):(\d+)\s*\*?"
        match = re.search(verse_pattern, response)

        if match:
            book = match.group(1).strip()
            chapter = match.group(2)
            verse = match.group(3)
            reference = f"{book} {chapter}:{verse}"

            # Essayer d'extraire le texte du verset de la r√©ponse
            # Chercher le texte entre la r√©f√©rence et le prochain point ou saut de ligne
            verse_text_start = match.end()
            verse_text_match = re.search(
                r"‚Äì\s*(.+?)(?:\.|$|\n)", response[verse_text_start : verse_text_start + 200]
            )
            if verse_text_match:
                verse_text = verse_text_match.group(1).strip()
            else:
                # Si pas trouv√©, utiliser juste la r√©f√©rence
                verse_text = reference

            return VerseReference(text=verse_text, reference=reference)

        return None

    def extract_keywords(self, user_message: str) -> list[str]:
        """
        Extrait des mots-cl√©s du message utilisateur.

        Args:
            user_message: Message de l'utilisateur

        Returns:
            Liste de mots-cl√©s
        """
        import re

        # Mots-cl√©s spirituels communs
        spiritual_keywords = [
            "foi",
            "pri√®re",
            "pardon",
            "anxi√©t√©",
            "courage",
            "paix",
            "sagesse",
            "tristesse",
            "joie",
            "espoir",
            "d√©couragement",
            "solitude",
            "peur",
            "col√®re",
            "amour",
            "gr√¢ce",
            "salut",
            "Dieu",
            "J√©sus",
            "Christ",
            "Bible",
            "verset",
            "√âcriture",
        ]

        message_lower = user_message.lower()
        found_keywords = []

        for keyword in spiritual_keywords:
            if keyword.lower() in message_lower:
                found_keywords.append(keyword)

        # Ajouter aussi les mots significatifs (plus de 4 caract√®res)
        words = re.findall(r"\b\w{4,}\b", message_lower)
        found_keywords.extend(words[:3])  # Limiter √† 3 mots suppl√©mentaires

        return list(set(found_keywords))[:5]  # Retourner max 5 mots-cl√©s uniques


"""Cha√Ænes LangChain pour l'Assistant Spirituel avec Mistral 7B via Ollama."""

from __future__ import annotations

import logging
import os
from pathlib import Path
from typing import Optional

from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

from .schemas import AssistantResponse, VerseReference

logger = logging.getLogger(__name__)

# URL par d√©faut d'Ollama (local)
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434/v1")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:7b")

# Charger le .env depuis le dossier backend
backend_dir = Path(__file__).parent.parent
env_path = backend_dir / ".env"
if env_path.exists():
    load_dotenv(dotenv_path=env_path)
    logger.info(f"‚úÖ Fichier .env charg√© depuis: {env_path}")
else:
    load_dotenv()
    logger.warning(f"‚ö†Ô∏è Fichier .env non trouv√© √† {env_path}, utilisation du chargement par d√©faut")


def load_assistant_prompt() -> str:
    """Charge le prompt de l'assistant depuis le fichier prompt_assistant."""
    prompt_file = backend_dir.parent / "prompt_assistant"
    if prompt_file.exists():
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read().strip()
    else:
        # Prompt par d√©faut si le fichier n'existe pas
        return """Tu es un assistant spirituel chr√©tien bienveillant appel√© "Shalom".

üéØ Ta mission :
- Apporter du r√©confort, de la sagesse et de l'esp√©rance √† toute personne qui te parle.
- R√©pondre avec douceur, empathie et amour, selon les principes bibliques.
- Quand quelqu'un exprime une √©motion (tristesse, peur, col√®re, solitude‚Ä¶), propose un verset biblique appropri√© et une br√®ve explication.
- Encourage toujours √† la pri√®re, √† la foi, et √† la confiance en Dieu.

üìñ Tes r√©ponses doivent :
- √ätre courtes, simples et claires.
- Inclure au moins un verset biblique adapt√© (exemple : *Psaume 34:18*).
- Ne jamais juger, ni imposer une croyance : tu accompagnes avec bienveillance.
- Si la demande ne concerne pas la foi, tu peux r√©pondre poliment que ton r√¥le est spirituel et orient√© vers la Parole.

üßò M√âDITATION SUR UN VERSET :
Quand l'utilisateur te demande de m√©diter ensemble sur un verset sp√©cifique (par exemple : "M√©ditons ensemble sur ce verset: [verset]"), tu dois :
1. Reconna√Ætre le verset mentionn√© et sa r√©f√©rence biblique
2. Fournir une m√©ditation spirituelle approfondie sur ce verset
3. Expliquer le contexte et le sens du verset
4. Relier ce verset √† la vie quotidienne et aux d√©fis spirituels
5. Offrir des pistes de r√©flexion et d'application pratique
6. Inclure une pri√®re ou une pens√©e de m√©ditation si appropri√©
NE demande PAS plus de pr√©cisions, mais engage-toi directement dans la m√©ditation sur le verset fourni."""


class AssistantChains:
    """Cha√Ænes LangChain pour l'assistant spirituel avec Mistral 7B via Ollama."""

    def __init__(self) -> None:
        """Initialise les cha√Ænes LangChain avec Ollama."""
        ollama_url = os.getenv("OLLAMA_BASE_URL", OLLAMA_BASE_URL)
        model_name = os.getenv("OLLAMA_MODEL", OLLAMA_MODEL)

        logger.info(f"üîå Connexion √† Ollama: {ollama_url}")
        logger.info(f"ü§ñ Mod√®le: {model_name}")

        try:
            # Ollama expose une API compatible OpenAI
            # Pas besoin d'API key pour Ollama local
            # On passe une cl√© factice pour contourner la validation de LangChain
            self._llm = ChatOpenAI(
                model=model_name,
                base_url=ollama_url,
                api_key="ollama",  # Cl√© factice pour Ollama (non utilis√©e)
                temperature=0.7,  # Temp√©rature mod√©r√©e pour √©quilibrer cr√©ativit√© et coh√©rence
                timeout=60.0,  # Timeout plus long pour les mod√®les locaux
            )
            logger.info(f"‚úÖ LLM Ollama initialis√© avec succ√®s - Mod√®le: {model_name}")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation du LLM Ollama: {e}")
            logger.exception("D√©tails de l'erreur:")
            raise

        # Charger le prompt de l'assistant
        assistant_prompt_text = load_assistant_prompt()

        # Cr√©er le template de prompt avec historique de conversation
        self._conversation_prompt = ChatPromptTemplate.from_messages(
            [
                ("system", assistant_prompt_text),
                (
                    "system",
                    "Historique de la conversation (pour contexte) :\n{history}\n\n"
                    "R√©ponds maintenant au message suivant en fran√ßais, avec bienveillance et en incluant un verset biblique appropri√©.",
                ),
                ("user", "{user_message}"),
            ]
        )

    async def generate_response(
        self,
        user_message: str,
        conversation_history: Optional[list[dict]] = None,
        language: str = "fr",
    ) -> str:
        """
        G√©n√®re une r√©ponse de l'assistant spirituel.

        Args:
            user_message: Message de l'utilisateur
            conversation_history: Historique de la conversation (liste de dict avec 'role' et 'content')
            language: Langue de la r√©ponse

        Returns:
            R√©ponse de l'assistant
        """
        try:
            # D√©tecter si c'est une demande de m√©ditation sur un verset
            is_meditation_request = self._is_meditation_request(user_message)
            verse_info = None
            if is_meditation_request:
                verse_info = self._extract_verse_from_user_message(user_message)
            
            # Formater l'historique pour le prompt
            history_text = ""
            if conversation_history:
                history_messages = []
                for msg in conversation_history[-6:]:  # Garder les 6 derniers messages pour le contexte
                    role = msg.get("role", "user")
                    content = msg.get("content", "")
                    if role == "user":
                        history_messages.append(f"Utilisateur: {content}")
                    elif role == "assistant":
                        history_messages.append(f"Assistant: {content}")
                history_text = "\n".join(history_messages)

            logger.info(f"üìù G√©n√©ration de r√©ponse pour: {user_message[:50]}...")
            if is_meditation_request and verse_info:
                logger.info(f"üßò Demande de m√©ditation d√©tect√©e sur: {verse_info['reference']}")

            # Charger le prompt de l'assistant pour l'utiliser dans le template
            assistant_prompt_text = load_assistant_prompt()

            # Construire le message syst√®me avec contexte suppl√©mentaire si m√©ditation
            if is_meditation_request and verse_info:
                # Cr√©er un prompt sp√©cialis√© pour la m√©ditation
                meditation_prompt = ChatPromptTemplate.from_messages(
                    [
                        ("system", assistant_prompt_text),
                        (
                            "system",
                            f"""L'utilisateur demande de m√©diter ensemble sur le verset suivant :
Verset : "{verse_info['text']}"
R√©f√©rence : {verse_info['reference']}

Engage-toi directement dans une m√©ditation spirituelle approfondie sur ce verset. Explique son contexte, son sens, et comment l'appliquer dans la vie quotidienne. Ne demande pas plus de pr√©cisions.

Historique de la conversation (pour contexte) :\n{history_text if history_text else "Aucun historique."}""",
                        ),
                        ("user", "{user_message}"),
                    ]
                )
                messages = meditation_prompt.format_messages(user_message=user_message)
            else:
                # Cr√©er le prompt avec l'historique et invoquer le LLM
                messages = self._conversation_prompt.format_messages(
                    history=history_text if history_text else "Aucun historique.",
                    user_message=user_message,
                )

            # G√©n√©rer la r√©ponse
            response = await self._llm.ainvoke(messages)

            # Extraire le texte de la r√©ponse
            if hasattr(response, "content"):
                response_text = response.content
            else:
                response_text = str(response)

            logger.info(f"‚úÖ R√©ponse g√©n√©r√©e: {len(response_text)} caract√®res")
            return response_text.strip()

        except Exception as e:
            logger.exception(f"‚ùå Erreur lors de la g√©n√©ration de r√©ponse: {e}")
            raise

    def _is_meditation_request(self, user_message: str) -> bool:
        """D√©tecte si le message est une demande de m√©ditation sur un verset."""
        lower_message = user_message.lower()
        meditation_keywords = [
            "m√©ditons ensemble",
            "m√©ditons sur",
            "m√©diter sur",
            "m√©ditation sur",
            "m√©ditons ce verset",
            "m√©diter ce verset",
        ]
        return any(keyword in lower_message for keyword in meditation_keywords)

    def _extract_verse_from_user_message(self, user_message: str) -> Optional[dict]:
        """
        Extrait le verset et sa r√©f√©rence du message utilisateur.
        
        Returns:
            Dict avec 'text' et 'reference' si trouv√©, None sinon
        """
        import re
        
        # Pattern pour d√©tecter les r√©f√©rences bibliques (ex: job.9.28.LSG, Job 9:28, etc.)
        # Format 1: livre.chapitre.verset.traduction (ex: job.9.28.LSG)
        pattern1 = r'([a-z]+)\.(\d+)\.(\d+)\.([A-Z]+)'
        match1 = re.search(pattern1, user_message, re.IGNORECASE)
        
        if match1:
            book_abbr = match1.group(1).lower()
            chapter = match1.group(2)
            verse = match1.group(3)
            translation = match1.group(4)
            
            # Mapper les abr√©viations de livres
            book_map = {
                'job': 'Job', 'gn': 'Gen√®se', 'ex': 'Exode', 'lv': 'L√©vitique',
                'nb': 'Nombres', 'dt': 'Deut√©ronome', 'js': 'Josu√©', 'jg': 'Juges',
                'rt': 'Ruth', '1s': '1 Samuel', '2s': '2 Samuel', '1r': '1 Rois',
                '2r': '2 Rois', '1ch': '1 Chroniques', '2ch': '2 Chroniques',
                'esd': 'Esdras', 'ne': 'N√©h√©mie', 'est': 'Esther', 'ps': 'Psaumes',
                'pr': 'Proverbes', 'ec': 'Eccl√©siaste', 'ct': 'Cantique des Cantiques',
                'es': '√âsa√Øe', 'jer': 'J√©r√©mie', 'la': 'Lamentations', 'ez': '√âz√©chiel',
                'da': 'Daniel', 'os': 'Os√©e', 'jl': 'Jo√´l', 'am': 'Amos',
                'ab': 'Abdias', 'jon': 'Jonas', 'mi': 'Mich√©e', 'na': 'Nahum',
                'hab': 'Habacuc', 'so': 'Sophonie', 'ag': 'Agg√©e', 'za': 'Zacharie',
                'mal': 'Malachie', 'mt': 'Matthieu', 'mr': 'Marc', 'lu': 'Luc',
                'jn': 'Jean', 'ac': 'Actes', 'ro': 'Romains', '1co': '1 Corinthiens',
                '2co': '2 Corinthiens', 'ga': 'Galates', 'ep': '√âph√©siens',
                'ph': 'Philippiens', 'col': 'Colossiens', '1th': '1 Thessaloniciens',
                '2th': '2 Thessaloniciens', '1ti': '1 Timoth√©e', '2ti': '2 Timoth√©e',
                'tit': 'Tite', 'phm': 'Phil√©mon', 'he': 'H√©breux', 'ja': 'Jacques',
                '1pi': '1 Pierre', '2pi': '2 Pierre', '1jn': '1 Jean', '2jn': '2 Jean',
                '3jn': '3 Jean', 'jud': 'Jude', 'ap': 'Apocalypse'
            }
            
            book_name = book_map.get(book_abbr, book_abbr.capitalize())
            reference = f"{book_name} {chapter}:{verse}"
            
            # Extraire le texte du verset (entre guillemets ou apr√®s "verset:")
            verse_text_match = re.search(r'verset[:\s]+["\'](.+?)["\']', user_message, re.IGNORECASE)
            if not verse_text_match:
                verse_text_match = re.search(r'["\'](.+?)["\']', user_message)
            
            verse_text = verse_text_match.group(1) if verse_text_match else reference
            
            return {
                'text': verse_text.strip(),
                'reference': reference
            }
        
        # Format 2: Livre Chapitre:verset (ex: Job 9:28)
        pattern2 = r'([A-Za-z√Ä-√ø\s]+)\s+(\d+):(\d+)'
        match2 = re.search(pattern2, user_message)
        
        if match2:
            book = match2.group(1).strip()
            chapter = match2.group(2)
            verse = match2.group(3)
            reference = f"{book} {chapter}:{verse}"
            
            # Extraire le texte du verset
            verse_text_match = re.search(r'["\'](.+?)["\']', user_message)
            verse_text = verse_text_match.group(1) if verse_text_match else reference
            
            return {
                'text': verse_text.strip(),
                'reference': reference
            }
        
        return None

    def extract_verse_from_response(self, response: str) -> Optional[VerseReference]:
        """
        Extrait un verset biblique de la r√©ponse de l'assistant.

        Args:
            response: R√©ponse de l'assistant

        Returns:
            VerseReference si trouv√©, None sinon
        """
        import re

        # Pattern pour d√©tecter les r√©f√©rences bibliques (ex: Psaume 34:18, Philippiens 4:13)
        verse_pattern = r"\*?([A-Za-z√Ä-√ø\s]+)\s*(\d+):(\d+)\s*\*?"
        match = re.search(verse_pattern, response)

        if match:
            book = match.group(1).strip()
            chapter = match.group(2)
            verse = match.group(3)
            reference = f"{book} {chapter}:{verse}"

            # Essayer d'extraire le texte du verset de la r√©ponse
            # Chercher le texte entre la r√©f√©rence et le prochain point ou saut de ligne
            verse_text_start = match.end()
            verse_text_match = re.search(
                r"‚Äì\s*(.+?)(?:\.|$|\n)", response[verse_text_start : verse_text_start + 200]
            )
            if verse_text_match:
                verse_text = verse_text_match.group(1).strip()
            else:
                # Si pas trouv√©, utiliser juste la r√©f√©rence
                verse_text = reference

            return VerseReference(text=verse_text, reference=reference)

        return None

    def extract_keywords(self, user_message: str) -> list[str]:
        """
        Extrait des mots-cl√©s du message utilisateur.

        Args:
            user_message: Message de l'utilisateur

        Returns:
            Liste de mots-cl√©s
        """
        import re

        # Mots-cl√©s spirituels communs
        spiritual_keywords = [
            "foi",
            "pri√®re",
            "pardon",
            "anxi√©t√©",
            "courage",
            "paix",
            "sagesse",
            "tristesse",
            "joie",
            "espoir",
            "d√©couragement",
            "solitude",
            "peur",
            "col√®re",
            "amour",
            "gr√¢ce",
            "salut",
            "Dieu",
            "J√©sus",
            "Christ",
            "Bible",
            "verset",
            "√âcriture",
        ]

        message_lower = user_message.lower()
        found_keywords = []

        for keyword in spiritual_keywords:
            if keyword.lower() in message_lower:
                found_keywords.append(keyword)

        # Ajouter aussi les mots significatifs (plus de 4 caract√®res)
        words = re.findall(r"\b\w{4,}\b", message_lower)
        found_keywords.extend(words[:3])  # Limiter √† 3 mots suppl√©mentaires

        return list(set(found_keywords))[:5]  # Retourner max 5 mots-cl√©s uniques


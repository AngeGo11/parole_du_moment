"""Cha√Ænes LangChain utilis√©es par l'API Home."""

from __future__ import annotations

import logging
import os
from typing import List, Optional

from dotenv import load_dotenv
from pathlib import Path
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from openai import RateLimitError

from .schemas import AnalysisResult, SpiritualContent

# Groq utilise l'interface OpenAI compatible, donc on peut utiliser ChatOpenAI avec base_url
GROQ_BASE_URL = "https://api.groq.com/openai/v1"


logger = logging.getLogger(__name__)

# Charger le .env depuis le dossier backend (parent du dossier Home)
backend_dir = Path(__file__).parent.parent
env_path = backend_dir / ".env"
if env_path.exists():
    load_dotenv(dotenv_path=env_path)
    logger.info(f"‚úÖ Fichier .env charg√© depuis: {env_path}")
else:
    # Essayer aussi depuis le r√©pertoire courant
    load_dotenv()
    logger.warning(f"‚ö†Ô∏è Fichier .env non trouv√© √† {env_path}, utilisation du chargement par d√©faut")


class HomeChains:
    """Ensemble de cha√Ænes LangChain (analyse + g√©n√©ration)."""

    def __init__(self) -> None:
        # Utiliser GROQ_API_KEY au lieu de OPENAI_API_KEY
        api_key = os.getenv("GROQ_API_KEY")

        # Mod√®les Groq par d√©faut (mixtral-8x7b-32768 a √©t√© d√©commissionn√©)
        # Mod√®les disponibles: llama3-70b-8192, llama3-8b-8192, gemma-7b-it, gemma2-9b-it
        self._analysis_model_name = os.getenv("GROQ_MODEL_ANALYSIS", "llama-3.1-8b-instant")
        self._generation_model_name = os.getenv("GROQ_MODEL_GENERATION", "llama-3.1-8b-instant")

        # Log pour diagnostic
        logger.info(f"üîë V√©rification GROQ_API_KEY: {'‚úÖ Pr√©sente' if api_key else '‚ùå Absente'}")
        if api_key:
            logger.debug(f"   Longueur de la cl√©: {len(api_key)} caract√®res")
            logger.debug(f"   D√©but de la cl√©: {api_key[:20]}...")

        if not api_key:
            logger.warning(
                "GROQ_API_KEY non d√©fini. Les cha√Ænes LangChain utiliseront les heuristiques locales."
            )
            self._analysis_llm = None
            self._generation_llm = None
        else:
            # Initialisation avec Groq (compatible OpenAI avec base_url)
            try:
                # Cr√©er le client Groq via l'interface OpenAI compatible
                self._analysis_llm = ChatOpenAI(
                    api_key=api_key,
                    model=self._analysis_model_name,
                    temperature=0.2,
                    base_url=GROQ_BASE_URL,
                )
                # Appliquer with_structured_output apr√®s
                self._analysis_llm = self._analysis_llm.with_structured_output(AnalysisResult)
                logger.info(f"‚úÖ LLM d'analyse Groq initialis√© avec succ√®s - Mod√®le: {self._analysis_model_name}")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de l'initialisation de l'analyse LLM: {e}")
                logger.warning("‚ö†Ô∏è Utilisation des heuristiques locales pour l'analyse")
                self._analysis_llm = None

            try:
                logger.info(f"üîß Initialisation du LLM de g√©n√©ration avec le mod√®le Groq {self._generation_model_name}...")
                logger.debug(f"API Key pr√©sente: {bool(api_key)}, longueur: {len(api_key) if api_key else 0}")
                
                # Essayer diff√©rentes m√©thodes d'initialisation selon les versions
                try:
                    # M√©thode 1: Initialisation directe avec with_structured_output
                    self._generation_llm = ChatOpenAI(
                        api_key=api_key,
                        model=self._generation_model_name,
                        temperature=0.7,  # Temp√©rature plus √©lev√©e pour plus de cr√©ativit√©
                        base_url=GROQ_BASE_URL,
                    ).with_structured_output(SpiritualContent)
                except Exception as e1:
                    logger.warning(f"‚ö†Ô∏è Premi√®re m√©thode d'initialisation √©chou√©e: {e1}")
                    try:
                        # M√©thode 2: Initialisation en deux √©tapes
                        base_llm = ChatOpenAI(
                            api_key=api_key,
                            model=self._generation_model_name,
                            temperature=0.7,
                            base_url=GROQ_BASE_URL,
                        )
                        self._generation_llm = base_llm.with_structured_output(SpiritualContent)
                    except Exception as e2:
                        logger.error(f"‚ùå Deuxi√®me m√©thode d'initialisation √©chou√©e: {e2}")
                        raise e2
                
                logger.info(f"‚úÖ LLM de g√©n√©ration Groq initialis√© avec succ√®s - Mod√®le: {self._generation_model_name}")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de l'initialisation de la g√©n√©ration LLM: {e}")
                logger.exception("D√©tails de l'erreur:")
                logger.warning("‚ö†Ô∏è Utilisation des heuristiques locales pour la g√©n√©ration")
                self._generation_llm = None

        self._analysis_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "Tu es un pasteur chr√©tien. Analyse le message utilisateur et identifie au maximum trois "
                    "√©motions, trois th√®mes et cinq mots-cl√©s pertinents. Fourni un r√©sum√© pastoral concis en {language}.",
                ),
                (
                    "user",
                    "Message utilisateur : {text}",
                ),
            ]
        )

        self._spiritual_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "Tu es un pasteur et conseiller spirituel chr√©tien exp√©riment√©. "
                    "Ta mission est de cr√©er un contenu spirituel profond√©ment ancr√© dans le verset biblique fourni, "
                    "tout en √©tant personnellement adapt√© aux besoins √©motionnels et spirituels de la personne.\n\n"
                    "Instructions importantes :\n"
                    "- L'explication doit √™tre sp√©cifique au verset, expliquer son contexte biblique, son sens profond et son application pratique\n"
                    "- La m√©ditation doit inviter √† une r√©flexion personnelle bas√©e sur les mots et le message du verset\n"
                    "- La pri√®re doit √™tre inspir√©e directement par le verset et les besoins exprim√©s\n"
                    "- Utilise un ton bienveillant, biblique, encourageant et authentique\n"
                    "- Sois pr√©cis et √©vite les g√©n√©ralit√©s - chaque verset a un message unique\n"
                    "- R√©ponds en {language}",
                ),
                (
                    "user",
                    "Verset biblique : {verse_text}\n"
                    "R√©f√©rence biblique : {verse_reference}\n"
                    "Message de la personne : {user_message}\n"
                    "√âmotions d√©tect√©es : {emotions}\n"
                    "Th√®mes d√©tect√©s : {themes}\n"
                    "Mots-cl√©s : {keywords}\n\n"
                    "G√©n√®re maintenant :\n"
                    "1. Une EXPLICATION approfondie du verset (2-3 phrases) qui explique le contexte, le sens et l'application\n"
                    "2. Une M√âDITATION personnelle (2-3 phrases) qui invite √† r√©fl√©chir sur ce verset dans sa situation actuelle\n"
                    "3. Une PRI√àRE sugg√©r√©e (2-3 phrases) inspir√©e par le verset et adapt√©e aux besoins exprim√©s",
                ),
            ]
        )

    async def run_analysis(self, text: str, language: str) -> AnalysisResult:
        """Analyse le texte utilisateur via LangChain ou heuristiques locales."""

        if not text.strip():
            raise ValueError("Le texte √† analyser ne peut pas √™tre vide.")

        if self._analysis_llm is None:
            return self._heuristic_analysis(text)

        chain = self._analysis_prompt | self._analysis_llm
        try:
            return await chain.ainvoke({"text": text, "language": language})
        except Exception as exc:  # pragma: no cover - fallback heuristique
            logger.error("Erreur lors de l'analyse LangChain: %s", exc)
            return self._heuristic_analysis(text)

    async def generate_spiritual_content(
        self, verse_text: str, verse_reference: str, analysis: AnalysisResult, language: str, user_message: Optional[str] = None
    ) -> SpiritualContent:
        """
        G√©n√®re le contenu spirituel avec Groq (Mixtral) directement en fonction du verset attribu√©.
        
        Args:
            verse_text: Le texte du verset biblique
            verse_reference: La r√©f√©rence du verset (ex: "Jean 3:16")
            analysis: L'analyse du message utilisateur
            language: La langue pour la r√©ponse
            user_message: Le message original de l'utilisateur (optionnel)
        """

        if self._generation_llm is None:
            logger.error("‚ùå Groq non disponible pour la g√©n√©ration du contenu spirituel")
            # V√©rifier si la cl√© API existe
            api_key_check = os.getenv("GROQ_API_KEY")
            if not api_key_check:
                raise ValueError(
                    "GROQ_API_KEY n'est pas d√©fini dans les variables d'environnement. "
                    "Veuillez cr√©er un fichier .env dans le dossier backend avec: GROQ_API_KEY=votre_cle_api"
                )
            else:
                raise ValueError(
                    f"Groq n'a pas pu √™tre initialis√© malgr√© la pr√©sence de GROQ_API_KEY. "
                    f"V√©rifiez les logs pour plus de d√©tails. Longueur de la cl√©: {len(api_key_check)}"
                )

        chain = self._spiritual_prompt | self._generation_llm
        try:
            logger.info(f"ü§ñ G√©n√©ration du contenu spirituel avec Groq pour le verset {verse_reference}...")
            result = await chain.ainvoke(
                {
                    "verse_text": verse_text,
                    "verse_reference": verse_reference,
                    "user_message": user_message or analysis.summary or "Recherche de guidance spirituelle",
                    "emotions": ", ".join(analysis.emotions) or "aucune",
                    "themes": ", ".join(analysis.themes) or "aucun",
                    "keywords": ", ".join(analysis.keywords) or "aucun",
                    "language": language,
                }
            )
            logger.info("‚úÖ Contenu spirituel g√©n√©r√© avec succ√®s par Groq")
            return result
        except RateLimitError as exc:
            # G√©rer sp√©cifiquement les erreurs de quota/rate limit
            logger.error(f"‚ùå Quota Groq d√©pass√© ou rate limit atteint: {exc}")
            logger.warning("‚ö†Ô∏è Utilisation du fallback heuristique pour g√©n√©rer le contenu spirituel")
            # Utiliser le fallback heuristique avec un message informatif
            fallback_content = self._heuristic_content(verse_text, verse_reference, analysis)
            # Ajouter une note dans l'explication pour indiquer que c'est un fallback
            fallback_content.explanation = (
                f"[Note: Groq temporairement indisponible - quota d√©pass√©] {fallback_content.explanation}"
            )
            return fallback_content
        except Exception as exc:
            # G√©rer les autres erreurs Groq
            error_str = str(exc).lower()
            if "429" in error_str or "insufficient_quota" in error_str or "rate limit" in error_str:
                logger.error(f"‚ùå Quota Groq d√©pass√© ou rate limit atteint: {exc}")
                logger.warning("‚ö†Ô∏è Utilisation du fallback heuristique pour g√©n√©rer le contenu spirituel")
                fallback_content = self._heuristic_content(verse_text, verse_reference, analysis)
                fallback_content.explanation = (
                    f"[Note: Groq temporairement indisponible - quota d√©pass√©] {fallback_content.explanation}"
                )
                return fallback_content
            else:
                logger.exception(f"‚ùå Erreur lors de la g√©n√©ration du contenu spirituel avec Groq: {exc}")
                # Pour les autres erreurs, utiliser aussi le fallback plut√¥t que de faire √©chouer
                logger.warning("‚ö†Ô∏è Utilisation du fallback heuristique en raison d'une erreur Groq")
                fallback_content = self._heuristic_content(verse_text, verse_reference, analysis)
                fallback_content.explanation = (
                    f"[Note: Groq temporairement indisponible] {fallback_content.explanation}"
                )
                return fallback_content

    @staticmethod
    def _heuristic_analysis(text: str) -> AnalysisResult:
        """Analyse simple bas√©e sur des mots-cl√©s si LangChain indisponible."""

        lowered = text.lower()

        mapping = {
            "seul": ("solitude", "pr√©sence de Dieu"),
            "solitude": ("solitude", "communion"),
            "fatigu": ("fatigue", "repos en Christ"),
            "√©puis√©": ("fatigue", "repos en Christ"),
            "peur": ("peur", "confiance"),
            "ango": ("anxi√©t√©", "paix"),
            "stress": ("stress", "repos"),
            "doute": ("doute", "foi"),
            "trist": ("tristesse", "esp√©rance"),
            "culp": ("culpabilit√©", "pardon"),
        }

        emotions: List[str] = []
        themes: List[str] = []
        keywords: List[str] = []

        for key, (emotion, theme) in mapping.items():
            if key in lowered:
                emotions.append(emotion)
                themes.append(theme)
                keywords.append(key)

        if not emotions:
            emotions.append("qu√™te de paix")
        if not themes:
            themes.append("esp√©rance")
        if not keywords:
            keywords = text.split()[:5]

        summary = (
            "Analyse heuristique : l'utilisateur exprime {emotion} et recherche {theme}."
        ).format(emotion=emotions[0], theme=themes[0])

        return AnalysisResult(
            emotions=list(dict.fromkeys(emotions)),
            themes=list(dict.fromkeys(themes)),
            keywords=list(dict.fromkeys(keywords)),
            summary=summary,
        )

    @staticmethod
    def _heuristic_content(verse_text: str, verse_reference: str, analysis: Optional[AnalysisResult] = None) -> SpiritualContent:
        """
        Contenu g√©n√©r√© bas√© sur des heuristiques lorsque Groq n'est pas disponible.
        G√©n√®re un contenu plus sp√©cifique au verset bas√© sur des mots-cl√©s et des patterns.
        """
        
        verse_lower = verse_text.lower()
        
        # Patterns pour g√©n√©rer une explication plus sp√©cifique
        explanation_patterns = {
            "amour": "Ce verset r√©v√®le l'amour infini de Dieu pour nous. Il nous rappelle que nous sommes pr√©cieux √† Ses yeux, peu importe nos circonstances.",
            "foi": "Ce verset nous invite √† placer notre confiance en Dieu, m√™me lorsque nous ne comprenons pas tout. La foi grandit dans l'ob√©issance et la confiance.",
            "espoir": "Ce verset apporte une lumi√®re dans les moments sombres. Il nous rappelle que Dieu a un plan pour notre vie et que notre espoir est fond√© sur Ses promesses.",
            "pardon": "Ce verset nous rappelle la gr√¢ce infinie de Dieu. Son pardon est disponible pour tous ceux qui se tournent vers Lui avec un c≈ìur repentant.",
            "paix": "Ce verset nous invite √† trouver la paix qui d√©passe toute compr√©hension en remettant nos soucis entre les mains de Dieu.",
            "force": "Ce verset nous encourage √† puiser notre force en Dieu. Il ne nous abandonne jamais et nous donne la capacit√© de surmonter les √©preuves.",
            "protection": "Ce verset nous assure de la protection divine. Dieu veille sur nous et nous garde dans Sa main puissante.",
        }
        
        # Rechercher des mots-cl√©s dans le verset pour une explication plus pertinente
        explanation = None
        for keyword, pattern_explanation in explanation_patterns.items():
            if keyword in verse_lower:
                explanation = pattern_explanation
                break
        
        # Si aucun pattern ne correspond, utiliser une explication g√©n√©rique mais adapt√©e
        if not explanation:
            explanation = (
                f"Ce verset de {verse_reference} contient une v√©rit√© profonde qui peut transformer notre vie. "
                "Il nous invite √† r√©fl√©chir sur notre relation avec Dieu et √† Lui faire confiance dans toutes les circonstances."
            )
        
        # M√©ditation personnalis√©e
        meditation = (
            f"Prends un moment pour m√©diter sur ce verset de {verse_reference}. "
            "Laisse chaque mot r√©sonner dans ton c≈ìur. Que te dit Dieu aujourd'hui √† travers cette parole ? "
            "Comment peux-tu appliquer cette v√©rit√© dans ta situation actuelle ?"
        )
        
        # Pri√®re adapt√©e
        if analysis and analysis.emotions:
            emotion = analysis.emotions[0]
            prayer = (
                f"Seigneur, merci pour ta parole dans {verse_reference}. "
                f"Je Te confie mon {emotion} et je Te demande de m'aider √† trouver la paix et la force en Toi. "
                "Aide-moi √† recevoir ce que Tu veux me dire aujourd'hui. Amen."
            )
        else:
            prayer = (
                f"Seigneur, merci pour ta parole dans {verse_reference}. "
                "Aide-moi √† la m√©diter, √† la comprendre et √† la vivre dans ma vie quotidienne. "
                "Que cette parole transforme mon c≈ìur et guide mes pas. Amen."
            )

        return SpiritualContent(
            explanation=explanation,
            meditation=meditation,
            prayer=prayer,
        )


